dim(z_agreed)
head(z_agreed)
z_agreed_score <- apply(x, 1, function(x, c1, c2){ x[c1]==x[c2]}, c1=1, c2="rfTest")
mean(z_agreed_score)
length(z_rf)
dim(x)
dim(z_agreed)
length(z_agreed_score)
z_agreed_score <- apply(z_agreed, 1, function(x, c1, c2){ x[c1]==x[c2]}, c1=1, c2="rfTest")
length(z_agreed_score)
mean(z_agreed_score)
mean(z_rf)
mean(z_gbm)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
AlzRf <- train(diagnosis~., method="rf", data=training)
AlzLda <- train(diagnosis~., method="lda", data=training)
AlzLda <- train(diagnosis~., method="gbm", data=training)
AlzLda_pred <- predict(AlzLDA, newdata=testing)
AlzLda_pred <- predict(AlzLda, newdata=testing)
AlzGbm_pred <- predict(gbm, newdata=testing)
AlzLda <- train(diagnosis~., method="lda", data=training)
AlzGbm <- train(diagnosis~., method="gbm", data=training)
AlzLda_pred <- predict(AlzLda, newdata=testing)
AlzGbm_pred <- predict(gbm, newdata=testing)
AlzGbm_pred <- predict(AlzGbm, newdata=testing)
AlzRf_pred <- predict(AlzRf, newdata=testing)
predComb <- as.data.frame(AlzGbm_pred,AlzLda_pred,AlzRf_pred,testing$diagnosis)
predComb <- as.data.frame(gbm=AlzGbm_pred,lda=AlzLda_pred,rf=AlzRf_pred,diagnosis=testing$diagnosis)
predComb <- as.data.frame("gbm"=AlzGbm_pred,"lda"=AlzLda_pred,"rf"=AlzRf_pred,"diagnosis"=testing$diagnosis)
?as.data.frame
predComb <- as.data.frame(cbind(AlzGbm_pred,AlzLda_pred,AlzRf_pred,testing$diagnosis),row.names = c("gbm","lda","rf","diagnosis"))
predCombFit <- train(diagnosis ~ ., method="rf", data=predComb)
length(AlzGbm_pred)
length(AlzRf_pred)
length(AlzLda_pred)
length(testing$diagnosis)
str(predComb)
predComb <- as.data.frame(cbind(AlzGbm_pred,AlzLda_pred,AlzRf_pred,testing$diagnosis),col.names = c("gbm","lda","rf","diagnosis"))
predCombFit <- train(diagnosis ~ ., method="rf", data=predComb)
str(predComb)
predComb <- as.data.frame(cbind(AlzGbm_pred,AlzLda_pred,AlzRf_pred,testing$diagnosis),col.names = c("gbm","lda","rf","diagnosis"))
predComb <- as.data.frame(cbind(AlzGbm_pred,AlzLda_pred,AlzRf_pred,testing$diagnosis),colnames = c("gbm","lda","rf","diagnosis"))
str(predComb)
predComb <- as.data.frame(cbind(AlzGbm_pred,AlzLda_pred,AlzRf_pred,testing$diagnosis),names = c("gbm","lda","rf","diagnosis"))
str(predComb)
names(predComb) <- c("gbm","lda","rf","diagnosis")
str(predComb)
predCombFit <- train(diagnosis ~ ., method="rf", data=predComb)
predCombFit_pred <- predict(predCombFit, newdata=testing)
predCombFit_pred <- predict(predCombFit, newdata=predComb)
length(predCombFit_pred)
final_pred <- cbind(predComb, predCombFit_pred)
str(final_pred)
predComb$gbm <- as.factor(predComb$gbm)
predComb$lda <- as.factor(predComb$lda)
predComb$rf <- as.factor(predComb$rf)
predComb$diagnosis <- as.factor(predComb$diagnosis)
predCombFit <- train(diagnosis ~ ., method="rf", data=predComb)
predCombFit_pred <- predict(predCombFit, newdata=predComb)
final_pred <- cbind(predComb, predCombFit_pred)
str(final_pred)
Alz_stacked <- apply(final_pred,1,function(x, c1, c2){x[c1]==x[c2]}, c1="diagnosis", c2="predCombFit_pred")
mean(Alz_stacked)
Alz_rf <- apply(final_pred,1,function(x, c1, c2){x[c1]==x[c2]}, c1="diagnosis", c2="rf")
Alz_gbm <- apply(final_pred,1,function(x, c1, c2){x[c1]==x[c2]}, c1="diagnosis", c2="gbm")
Alz_lda <- apply(final_pred,1,function(x, c1, c2){x[c1]==x[c2]}, c1="diagnosis", c2="lda")
mean(Alz_rf)
mean(Alz_lda)
mean(Alz_gbm)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
concFit <- train(CompressiveStrength ~ ., method="lasso", data=training)
install.packages("elasticnet")
install.packages("lars")
install.packages("elasticnet")
concFit <- train(CompressiveStrength ~ ., method="lasso", data=training)
?plot.enet
plot(concFit, xvar="penalty")
plot(concFit, xvar=c("fraction", "penalty", "L1norm", "step"))
concFit
concFit$finalModel
print(concFit$finalModel)
plot(concFit$finalModel, xvar=c("penalty"))
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
install.packages("RcppArmadillo")
install.packages("forecast")
library(forecast)
modTrain <- bats(tstrain)
tstest <- ts(testing$visitsTumblr)
predtumblr <- predict(modTrain, newdata=tstest)
predtumblr
training
predtumblr <- forecast(tstrain)
predtumblr
accuracy(predtumblr, testing)
accuracy(predtumblr, ts(testing))
?forecast
tstrain
tstest
predtumblr <- forecast(tstrain, h=dim(tstest), level=.95)
dim(tstest)
predtumblr <- forecast(tstrain, h=dim(testing), level=.95)
dim(testing)
predtumblr <- forecast(tstrain, h=dim(testing)[1], level=.95)
predtumblr
predtumblr <- forecast(modTrain, h=dim(testing)[1], level=.95)
predtumblr
summary(predtumblr)
sum(predtumblr$lower>testing$visitsTumblr & predtumblr$upper> testing$visitsTumblr)/ dim(testing)[1]
sum(predtumblr$lower>testing$visitsTumblr && predtumblr$upper> testing$visitsTumblr)/ dim(testing)[1]
sum(predtumblr$lower<testing$visitsTumblr & predtumblr$upper< testing$visitsTumblr)/ dim(testing)[1]
sum(predtumblr$lower>testing$visitsTumblr & predtumblr$upper<testing$visitsTumblr)/ dim(testing)[1]
sum(predtumblr$lower>testing$visitsTumblr & predtumblr$upper>testing$visitsTumblr)/ dim(testing)[1]
sum(predtumblr$lower<testing$visitsTumblr & predtumblr$upper>testing$visitsTumblr)/ dim(testing)[1]
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testin
testing <- concrete[-inTrain]
set.seed(325)
modFit <- svm(CompressiveStrength ~ .,data=training)
predConc <- predict(modFit, newdata=testing)
testing <- concrete[-inTrain,]
predConc <- predict(modFit, newdata=testing)
confusionMatrix(predConc, testing$CompressiveStrength)
accuracy(predConc, testing$CompressiveStrength)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= '~/Desktop/coursera/Assignments/PML')
#set up libraries
library(caret)
library(ggplot2)
library(rpart)
library(tree)
#load data
trainingdata <- read.csv('./data/pml-training.csv')
problem <- read.csv('./data/pml-testing.csv')
#remove X and username
trainingdata <- subset(trainingdata, select=!(names(trainingdata) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window','num_window')))
#remove columns that are mainly missing.data
a <- sapply(trainingdata,function(x){ sum(is.na(x))} )
trainingdata <- subset(trainingdata, select=!(names(trainingdata) %in% names(a[a>0])))
#convert factor variables to numeric for PCA
a <- sapply(names(trainingdata),function(x) {ifelse(x=='classe','numeric',class(trainingdata[,x]))})
a <- a[a=="factor"]
a <- names(a)
trainingdata[,a] <- as.numeric(unlist(trainingdata[,a]))
#split trainingdata into train and test
set.seed(123321)
intrain <- createDataPartition(trainingdata$classe, p=0.7, list=FALSE)
train <- trainingdata[intrain,]
test <- trainingdata[-intrain,]
modelRPART <- rpart(classe ~ ., method="class", data=train)
printcp(modelRPART)
print(modelRPART)
confusionMatrix(train$classe, predict(modelRPART, newdata=train ))
?predict.rpart
confusionMatrix(train$classe, predict(modelRPART, newdata=train, type="class" ))
library(randomForest)
?randomForest
modelRF <- randomForest(classe ~ ., data=train, importance=TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= '~/Desktop/coursera/Assignments/PML')
modelRF <- randomForest(classe ~ ., data=train)
library(randomForest)
str(train)
modelRF <- randomForest(classe ~ ., data=train)
modelRF <- randomForest(classe ~ ., data=train, ntree=10)
modelRF$forest
library(caret)
confusionMatrix(train$classe,predict(modelRF, newdata=train))
confusionMatrix(train$classe,predict(modelRF, newdata=test))
confusionMatrix(test$classe,predict(modelRF, newdata=test))
predict(modelRF, newdata = problem)
problem <- subset(problem, select=!(names(problem) %in% names(train)))
a <- sapply(names(problem),function(x) {ifelse(x=='classe','numeric',class(problem[,x]))})
a <- a[a=="factor"]
a <- names(a)
problem[,a] <- as.numeric(unlist(problem[,a]))
predict(modelRF, newdata = problem)
problem <- read.csv('./data/pml-testing.csv')
problem <- subset(problem, select=!(names(problem) %in% names(train)))
problem <- read.csv('./data/pml-testing.csv')
problem <- subset(problem, select=!(names(problem) %in% names(trainingdata)))
problem <- subset(problem, select=!(names(problem) %in% names(train)))
str(problem)
problem <- read.csv('./data/pml-testing.csv')
problem <- subset(problem, select=(names(problem) %in% names(train)))
predict(modelRF, newdata = problem)
problem <- read.csv('./data/pml-testing.csv')
summary(problem)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= '~/Desktop/coursera/Assignments/PML')
#set up libraries
library(caret)
library(ggplot2)
library(rpart)
library(randomForest)
#load data
trainingdata <- read.csv('./data/pml-training.csv')
problem <- read.csv('./data/pml-testing.csv')
trainingdata <- subset(trainingdata, select=!(names(trainingdata) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window','num_window')))
problem <- subset(problem, select=!(names(problem) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window','num_window')))
a <- sapply(problem,function(x){ sum(is.na(x))} )
problem <- subset(problem, select=!(names(problem) %in% names(a[a==20])))
trainingdata <- subset(trainingdata, select=(names(trainingdata) %in% names(problem)))
sapply(trainingdata,function(x){ sum(is.na(x))} )
str(trainingdata)
str(problem)
#load data
trainingdata <- read.csv('./data/pml-training.csv')
problem <- read.csv('./data/pml-testing.csv')
trainingdata <- subset(trainingdata, select=!(names(trainingdata) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window','num_window')))
problem <- subset(problem, select=!(names(problem) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window','num_window')))
a <- sapply(problem,function(x){ sum(is.na(x))} )
problem <- subset(problem, select=!(names(problem) %in% names(a[a==20])))
trainingdata <- subset(trainingdata, select=(names(trainingdata) %in% c(names(problem),'classe')))
#remove X and username
trainingdata <- subset(trainingdata, select=!(names(trainingdata) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window','num_window')))
problem <- subset(problem, select=!(names(problem) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window','num_window')))
a <- sapply(problem,function(x){ sum(is.na(x))} )
problem <- subset(problem, select=!(names(problem) %in% names(a[a==20])))
trainingdata <- subset(trainingdata, select=(names(trainingdata) %in% c(names(problem),'classe')))
#convert factor variables to numeric for PCA
#a <- sapply(names(trainingdata),function(x) {ifelse(x=='classe','numeric',class(trainingdata[,x]))})
#a <- a[a=="factor"]
#a <- names(a)
#trainingdata[,a] <- as.numeric(unlist(trainingdata[,a]))
#split trainingdata into train and test
set.seed(123321)
intrain <- createDataPartition(trainingdata$classe, p=0.7, list=FALSE)
train <- trainingdata[intrain,]
test <- trainingdata[-intrain,]
modelRPART <- rpart(classe ~ ., method="class", data=train)
modelRF <- randomForest(classe ~ ., data=train, ntree=10)
confusionMatrix(train$classe,predict(modelRF, newdata=train))
confusionMatrix(test$classe,predict(modelRF, newdata=test))
predict(modelRF, newdata = problem)
plotcp(modelRF)
#set up libraries
library(caret)
library(ggplot2)
library(rpart)
library(randomForest)
plotcp(modelRF)
plot(modelRF)
modelRF
#PreProcess
#preProc <- preProcess(train[,-86], method="pca")
#trainPC <- predict(preProc, newdata=train )
#Fit CART
modelRPART <- rpart(classe ~ ., method="class", data=train)
modelRF <- randomForest(classe ~ ., data=train, ntree=20)
confusionMatrix(train$classe,predict(modelRF, newdata=train))
confusionMatrix(test$classe,predict(modelRF, newdata=test))
predict(modelRF, newdata = problem)
modelRF$predicted
modelRF$err.rate
modelRF$importance
sort(modelRF$importance, descending=TRUE)
sort(modelRF$importance, decreasing = TRUE)
sort(modelRF$importance, decreasing = TRUE)[1:10]
names(sort(modelRF$importance, decreasing = TRUE)[1:10])
class(modelRF$importance)
names(sort(as.dataframe(modelRF$importance), decreasing = TRUE)[1:10])
names(sort(as.data.frame(modelRF$importance), decreasing = TRUE)[1:10])
sort(as.data.frame(modelRF$importance), decreasing = TRUE)[1:10]
as.data.frame(modelRF$importance)
a <- as.data.frame(modelRF$importance)
names(a)
rownames(modelRF$importance)
rownames(sorted(modelRF$importance))
rownames(sort(modelRF$importance))
rownames(a)
a <- sort(a, decreasing = TRUE)[1:10]
a <- sort(a, decreasing = TRUE)
a <- sort(a$MeanDecreaseGini, decreasing = TRUE)
a
rownames(a)
a <- as.data.frame(modelRF$importance)
order(a, decreasing = TRUE)
a <- a[order(a, decreasing = TRUE)]
a <- a[order(a, decreasing = TRUE),]
a
a <- as.data.frame(modelRF$importance)
a <- a[order(a, decreasing = TRUE),]
a <- modelRF$importance
a <- as.data.frame(modelRF$importance)
a[order(a$MeanDecreaseGini),]
b <- order(a$MeanDecreaseGini, decreasing = TRUE)
b[1:2]
c <- modelRF$importance[b[1:5]]
c
c <- modelRF$importance[b[1:5],]
c
?featurePlot
featurePlot(train[,names(c)], train$classe, "pairs")
importance(modelRF)
varImpPlot(modelRF, type=2)
varImpPlot(modelRF, type=2, col=1, cex=0.5)
varImpPlot(modelRF, type=2, col=1, cex=0.8)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= '~/Desktop/coursera/Assignments/PML')
#set up libraries
library(caret)
library(ggplot2)
library(rpart)
library(randomForest)
#load data
trainingdata <- read.csv('./data/pml-training.csv')
problem <- read.csv('./data/pml-testing.csv')
#remove X and username
trainingdata <- subset(trainingdata, select=!(names(trainingdata) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window','num_window')))
problem <- subset(problem, select=!(names(problem) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window','num_window')))
a <- sapply(problem,function(x){ sum(is.na(x))} )
problem <- subset(problem, select=!(names(problem) %in% names(a[a==20])))
trainingdata <- subset(trainingdata, select=(names(trainingdata) %in% c(names(problem),'classe')))
#split trainingdata into train and test
set.seed(123321)
intrain <- createDataPartition(trainingdata$classe, p=0.7, list=FALSE)
train <- trainingdata[intrain,]
test <- trainingdata[-intrain,]
modelRPART <- rpart(classe ~ ., data = train, method="class")
confusionMatrix(train$classe,predict(modelRPART, newdata=train))
confusionMatrix(train$classe,predict(modelRPART, newdata=train, type="class"))
#Fit RF
modelRF <- randomForest(classe ~ ., data=train, ntree=20)
confusionMatrix(train$classe,predict(modelRF, newdata=train))
confusionMatrix(test$classe,predict(modelRF, newdata=test))
varImpPlot(modelRF, type=2, col=1, cex=0.8)
predict(modelRF, newdata = problem)
library(shiny)
runApp('Desktop/coursera/shiny/test')
runApp('Desktop/coursera/shiny/test')
install.packages("UsingR")
runApp('Desktop/coursera/shiny/test')
runApp('Desktop/coursera/shiny/test')
runApp('Desktop/coursera/shiny/test')
source('~/.active-rstudio-document')
install.packages("miniUI")
source('~/.active-rstudio-document')
install.packages("plotly")
?plotly
library(plotly)
?plotly
?(.Rprofile)
help("Rprofile")
Sys.getenv()
library(plotly)
traffic <- read.csv("TrafficSignals.csv")
View(traffic)
table(traffic$Crossing_Facility)
?grep
traffic$Crossing_Facility <- gsub("P(ed|ED).*","PEDESTRIAN",traffic$Crossing_Facility)
table(traffic$Crossing_Facility)
traffic$Crossing_Facility <- gsub("P(uf|UF).*","PUFFIN",traffic$Crossing_Facility)
table(traffic$Crossing_Facility)
traffic$Crossing_Facility <- gsub("","NA",traffic$Crossing_Facility)
table(traffic$Crossing_Facility)
traffic <- read.csv("TrafficSignals.csv")
traffic$Crossing_Facility <- gsub("P(ed|ED).*","PEDESTRIAN",traffic$Crossing_Facility)
traffic$Crossing_Facility <- gsub("P(uf|UF).*","PUFFIN",traffic$Crossing_Facility)
traffic["Crossing_Facility"==""] <-"NA"
table(traffic$Crossing_Facility)
traffic[traffic$Crossing_Facility==""] <-"NA"
traffic[traffic$Crossing_Facility=="",traffic$Crossing_Facility] <-"NA"
traffic[traffic$Crossing_Facility=="",] <-"NA"
traffic <- read.csv("TrafficSignals.csv")
traffic$Crossing_Facility <- gsub("P(ed|ED).*","PEDESTRIAN",traffic$Crossing_Facility)
traffic$Crossing_Facility <- gsub("P(uf|UF).*","PUFFIN",traffic$Crossing_Facility)
traffic[,traffic$Crossing_Facility==""] <-"NA"
traffic$Crossing_Facility[traffic$Crossing_Facility==""] <-"NA"
table(traffic$Crossing_Facility)
table(traffic$Type)
?qplot
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility)
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility)
ggTraffic
?theme
?element_text
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility) + theme_classic(axis.text.x=element_text(angle = 90))
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility) + theme_classic(axis.title.x=element_text(angle = 90))
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility) + theme(axis.title.x=element_text(angle = 90))
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility) + theme(axis.text.x=element_text(angle = 90))
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility, ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90))
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90))
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings", legend="dd") + theme(axis.text.x=element_text(angle = 90))
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + labs(legend="Crossing Facility")
ggTraffic
?labs
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + labs(scale_x_discrete(name ="Crossing Facility"))
ggTraffic
summary(ggTraffic)
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + scale_x_discrete(name ="Crossing Facility")
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + scale_x_continuous(name ="Crossing Facility")
ggTraffic
?scale_x_discrete
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + scale_x_discrete(labels ="Crossing Facility")
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + scale_x_discrete(labels =NULL)
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + scale_y_discrete(labels ="X")
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + labs(fill="Facility")
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + labs(fill="Facility", colour="Facility")
ggTraffic
ggTraffic <- qplot(Type, data=traffic, colour=Crossing_Facility, fill=Crossing_Facility,xlab="Crossing Type", ylab="Number of Crossings") + theme(axis.text.x=element_text(angle = 90)) + labs(fill="Facility", colour="Facility")
ggplotly(ggTraffic)
shiny::runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
HR <- read.csv('IBMHR.csv')
HR <- HR %>% select(-(EmployeeCount:EmployeeNumber))
trainIndex <- createDataPartition(HR$Attrition, list = FALSE, p=0.7)
trainX <- HR[trainIndex, -Attrition]
trainY <- HR[trainIndex, Attrition]
testX <- HR[-trainIndex, -Attrition]
testy <- HR[-trainIndex, Attrition]
?randomForest
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
fitmodel()
runApp('Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
setwd('~/Desktop/coursera/Assignments/DDP/DDP-WK4/DDP-WK4')
#import data
HR <- read.csv('IBMHR.csv')
HR <- HR %>% select(-(EmployeeCount:EmployeeNumber))
trainIndex <- createDataPartition(HR$Attrition, list = FALSE, p=0.7)
trainX <- HR[trainIndex,] %>% select(-Attrition)
trainY <- HR[trainIndex,] %>% select(Attrition)
testX <- HR[-trainIndex,] %>% select(-Attrition)
testy <- HR[-trainIndex,] %>% select(Attrition)
x <- train(x=trainX, y=trainY, method="rf", ntree=5,
importance=TRUE )
x <- train(x=trainX, y=trainY, method="rf", ntree=5)
x <- train(x=as.data.frame(trainX), y=as.data.frame(trainY), method="rf", ntree=5)
x <- train(x=trainX, y=as.factor(trainY), method="rf", ntree=5)
x <- train(x=trainX, y=make.names(trainY), method="rf", ntree=5)
length(trainY)
class(trainY)
dim(trainY)
x <- train(x=trainX, y=trainY[1], method="rf", ntree=5)
x <- train(x=trainX, y=trainY[[1]], method="rf", ntree=5)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("shinythemes")
runApp()
runApp()
runApp()
install.packages("rsconnect")
install.packages("rsconnect")
rsconnect::setAccountInfo(name='simbosky',
token='F100FE9F45FA4A1E1E4EB1D8860CE920',
secret='Da49keL7hfax9G/9+PXjVdWccOv2i5APNevw1FFu')
library(rsconnect)
deployApp(getwd())
